{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CORE _TASK2_Teena Joseph.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2IBOToH0jgy"
      },
      "source": [
        "#**The Entreprenuership Network**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYPFo03nukNL"
      },
      "source": [
        "#**Core Task 2: Face Recognition System using opencv**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35aOWvxD03Ov"
      },
      "source": [
        "**Author Name : Teena Joseph(MSC DA), Rajagiri College of Social Sciences**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coRrobrtuTfR"
      },
      "source": [
        "pip install face_recognition"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjAzHDs818Rg"
      },
      "source": [
        "import cv2\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFI8nXwj26YF"
      },
      "source": [
        "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml - GitHub')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5S0jVu2uZHD9"
      },
      "source": [
        "def face_extractor(img):\n",
        "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
        "    faces = face_classifier.detectMultiScale(gray,1.3,5)\n",
        "\n",
        "    if faces is():\n",
        "      return None\n",
        "\n",
        "    for(x,y,w,h) in faces:\n",
        "      cropped_face = img[y:y+h, x:x+w]\n",
        "  \n",
        "    return cropped_face\n",
        "\n",
        "cap = cv2.VideoCapture(0)\n",
        "count = 0"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XN9TfKDu4MeY"
      },
      "source": [
        "while True:\n",
        "  ret, frame = cap.read()\n",
        "  if face_extractor(frame) is not None:\n",
        "    count+=1\n",
        "    face = cv2.resize(face_extractor(frame),(200,200))\n",
        "    face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
        "    file_name_path = 'faces/user'+str(count)+'.jpg'\n",
        "    cv2.imwrite(file_name_path,face)\n",
        "    cv2.putText(face,str(count),(50,50),cv2.FONT_HERSHEY_COMPLEX,1,(0,255,0),2)\n",
        "    cv2.imshow('Face Cropper',face)\n",
        "  else:\n",
        "      print(\"Face not Found\")\n",
        "      pass\n",
        "      if cv2.waitKey(1)==13 or count==100:\n",
        "        break\n",
        "        cap.release()\n",
        "        cv2.destroyAllWindows()\n",
        "        print('Colleting Samples Complete!!!')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}